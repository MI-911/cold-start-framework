{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'fmf', 'dqn-knn', 'ppr-linear-learned', 'ppr-joint', 'ppr-linear-joint-learned', 'ddpg-ppr-collab', 'dqn-ppr-joint', 'ddpg-ppr-kg', 'ddpg-mf', 'random', 'top-pop', 'knn', 'ppr-collab', 'ppr-kg', 'mf', 'lrmf', 'dqn-mf', 'ddpg-ppr-joint', 'ddpg-knn', 'melu'}\n",
      "['knn', 'mf', 'ppr-collab', 'ppr-joint', 'ppr-kg', 'ppr-linear-learned']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from requests import get\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.style.use('seaborn-deep')\n",
    "metric = 'hr'\n",
    "cutoff = 10\n",
    "n_questions = 5\n",
    "de_only = True\n",
    "experiment_subset = 'uniform'\n",
    "\n",
    "\n",
    "data = get(f'https://mindreader.tech/spectate/results/{experiment_subset}/{metric}/{cutoff}').json()\n",
    "data = {k: v for k, v in data.items() if not 'grid' in k}\n",
    "\n",
    "metric = metric.replace('cov', 'div') if metric == 'cov' else metric  # Hack job :-)\n",
    "interviewer_kinds = ['greedy-adaptive-', 'greedy-', 'pop-'] #, 'dqn-', 'ddpg-']\n",
    "\n",
    "def replace_all(string, lst):\n",
    "    for item in lst:\n",
    "        string = string.replace(item, '')\n",
    "    \n",
    "    return string\n",
    "\n",
    "unique_models = set([replace_all(model, interviewer_kinds) for model in data.keys()])\n",
    "if de_only:\n",
    "    unique_models = set([model.replace('-rec', '') for model in unique_models])\n",
    "else:\n",
    "    unique_models = set([model for model in unique_models if model.endswith('-rec')])\n",
    "\n",
    "print(unique_models)\n",
    "unique_models = sorted(set([model for model in unique_models if all([f'{interviewer}{model}' in data for interviewer in interviewer_kinds])]))\n",
    "print(unique_models)\n",
    "\n",
    "# Hack job again\n",
    "interviewer_kinds += ['dqn-', 'ddpg-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ddpg-knn [[0.4009216589861751, 0.5253456221198156, 0.5368663594470046, 0.535796766743649]]\n",
      "ddpg-mf [[0.6382488479262672, 0.6175115207373272, 0.6152073732718893, 0.6374133949191686]]\n",
      "ddpg-ppr-collab []\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d77366d69d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mdes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_questions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mdes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ],
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "\n",
    "fig_width = 16  # Increase if bars become to small to see \n",
    "fig_height = 5\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "ind = np.arange(len(unique_models))\n",
    "bar_group_width = .17\n",
    "\n",
    "model_map = {'ppr-linear-learned': 'ppr-linear'}\n",
    "label_map = {'greedy-adaptive-': 'AdaptiveGreedy', 'greedy-': 'FixedGreedy', 'pop-': 'FixedPop', 'dqn-': 'DQN', 'ddpg-': 'DDPG'}\n",
    "\n",
    "legend_handles = []\n",
    "\n",
    "statistical_significances = []\n",
    "\n",
    "plt.axhline(y=np.mean(data['top-pop'][n_questions - 1]), linestyle='--')\n",
    "def pad_to_length(lst, l): \n",
    "    if len(lst) < l: \n",
    "        remaining = len(lst) - l\n",
    "        [lst.append(lst[-1]) for _ in range(remaining)]\n",
    "        \n",
    "    return lst\n",
    "\n",
    "\n",
    "# Add bar sets\n",
    "for idx, kind in enumerate(interviewer_kinds):\n",
    "    \n",
    "    def model_str(kind, model, rec): \n",
    "        return f'{kind}{model}-rec' if rec else f'{kind}{model}'\n",
    "    \n",
    "    des = []\n",
    "    res = []\n",
    "    \n",
    "    for model in unique_models: \n",
    "        ms = model_str(kind, model, False)\n",
    "        ms_rec = model_str(kind, model, True)\n",
    "        \n",
    "        if ms in data:\n",
    "            if 'ddpg' in ms: \n",
    "                print(ms, data[ms])\n",
    "            if len(data[ms]) == n_questions: \n",
    "                des.append(data[ms][n_questions - 1])\n",
    "            else: \n",
    "                des.append(data[ms][-1])\n",
    "                \n",
    "        else: \n",
    "            des.append(np.zeros((len(unique_models), 4)))\n",
    "            \n",
    "        if ms_rec in data: \n",
    "            if len(data[ms_rec]) == n_questions: \n",
    "                res.append(data[ms_rec][n_questions - 1])\n",
    "            else: \n",
    "                res.append(data[ms_rec][-1])\n",
    "                \n",
    "        else: \n",
    "            res.append(np.zeros((len(unique_models), 4)))\n",
    "    \n",
    "    # des = [data[model_str(kind, model, False)][n_questions - 1] if model_str(kind, model, False) in data else np.zeros((len(unique_models), 4)) for model in unique_models]\n",
    "    # res = [data[model_str(kind, model, True)][n_questions - 1] if model_str(kind, model, True) in data else np.zeros((len(unique_models), 4)) for model in unique_models]\n",
    "        \n",
    "    # Descriptive entity interview performance\n",
    "    y = [np.mean(de) for de in des]\n",
    "    y_std = [np.std(de) for de in des]\n",
    "    \n",
    "    # Recommendable entity interview performance\n",
    "    y_rec = [np.mean(re) for re in res]\n",
    "    y_rec_std = [np.std(re) for re in res]\n",
    "    \n",
    "    # Calculate indentation\n",
    "    bar_width_fraction = 0.4  # Decrease to increase spacing between bar pairs - 0.5 leaves no space \n",
    "    bar_width = bar_group_width * bar_width_fraction\n",
    "    descriptive_indent = ind + idx * bar_group_width\n",
    "    recommendable_indent = descriptive_indent + bar_width\n",
    "    \n",
    "    # Check for statistical significant change\n",
    "#     for de, re in zip(des, res): \n",
    "#         t, p_value = ttest_rel(de, re)\n",
    "#         statistical_significances.append(p_value <= 0.05)\n",
    "            \n",
    "    # Create bar pairs\n",
    "    ax.bar(descriptive_indent, y, width=bar_width, yerr=y_std, color=f'C{idx}', zorder=3)\n",
    "    ax.bar(recommendable_indent, y_rec, alpha=0.6, width=bar_width, zorder=3, \n",
    "           yerr=y_rec_std, color=f'C{idx}', ecolor=(0,0,0,0.5), \n",
    "           edgecolor='white', linewidth=0, hatch='\\\\\\\\\\\\')\n",
    "            \n",
    "    # Store the legend handles so we can add some more manually later\n",
    "    legend_handles.append(mpatches.Patch(color=f'C{idx}', label=label_map.get(kind)))\n",
    "    \n",
    "\n",
    "# Add outline if there is statistical significance\n",
    "children = ax.get_children()\n",
    "\n",
    "# Error bars are the first children, so skip those\n",
    "# n_error_bar_sets = n_interviewer_kinds * 2\n",
    "# n_to_skip = n_error_bar_sets\n",
    "\n",
    "\n",
    "# n_interviewer_kinds = len(interviewer_kinds)\n",
    "# n_models = len(unique_models)\n",
    "# n_bars = (n_models * n_interviewer_kinds)\n",
    "\n",
    "# bar_pair_indices = []\n",
    "\n",
    "# for i in range(n_interviewer_kinds * 2): \n",
    "#     if not i % 2 == 0: \n",
    "#         continue\n",
    "#     for m in range(n_models): \n",
    "#         interviewer_skip = i * n_models\n",
    "#         de_bar_index = n_to_skip + interviewer_skip + m\n",
    "#         re_bar_index = de_bar_index + n_models\n",
    "#         bar_pair_indices.append((de_bar_index, re_bar_index))\n",
    "\n",
    "# for i, (de, re) in enumerate(bar_pair_indices): \n",
    "#     is_significant = statistical_significances[i]\n",
    "#     if is_significant: \n",
    "#         children[de].set_edgecolor('black')\n",
    "#         children[de].set_linewidth(2)\n",
    "#         children[re].set_edgecolor('black')\n",
    "#         children[re].set_linewidth(2)\n",
    "\n",
    "        \n",
    "# Draw the figure\n",
    "model_displays = [model.replace('-rec', '') for model in unique_models]\n",
    "model_displays = map(lambda model: model_map.get(model, model).upper(), model_displays)\n",
    "\n",
    "ax.set_xticks(ind + bar_group_width)\n",
    "ax.set_xticklabels(model_displays)\n",
    "# ax.set_ylim(0, 0.5)\n",
    "\n",
    "plt.ylabel(f'{metric.upper()}@{cutoff}')\n",
    "interview_kind = 'DE' if de_only else 'RE'\n",
    "plt.title(f'Ranking quality for {n_questions}-length interviews')\n",
    "\n",
    "# Add legend patches for the full color/transparent w. stripes to describe what they mean\n",
    "full_black = mpatches.Patch(color=(0,0,0, 1.), label='Desc. entities')\n",
    "transparent_black = mpatches.Patch(color=(0,0,0, .4), label='Rec. entities', hatch='\\\\\\\\\\\\')\n",
    "\n",
    "# Create legend with explicit handles\n",
    "plt.legend(handles=legend_handles, loc='upper left', ncol=2)\n",
    "\n",
    "plt.grid(True, zorder=0)\n",
    "plt.savefig(f'output/{experiment_subset}_{interview_kind.lower()}_{metric}{cutoff}_interviewer_comparison.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}